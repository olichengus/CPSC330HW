{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material Anomaly Detection\n",
    "\n",
    "This project aims to leverage pre-trained Deep Convolutional Neural Networks to solve the problem of anomaly detection in material a material based settings. This is a common problem in the field that we work in, and is in essence a binary classification problem.\n",
    "\n",
    "Although this tends to be very easy in the case of two distinct labelled classes where ample examples are present it can be very challenging and open ended if no examples of the negative (failure) class are available. This is a common problem in manufacturing settings where reliability creates a situation where thousands of normal examples are present for each abnormal example.\n",
    "\n",
    "Key Tools/Libraries and Concepts:\n",
    "- Pytorch and torchvision models (pretrained models), you can use another framework if you find that easier\n",
    "- Transfer learning to train classifier layers on top of pretrained backbones\n",
    "- Residual networks explanation (resnets) https://www.youtube.com/watch?v=o_3mboe1jYI&ab_channel=rupertai\n",
    "\n",
    "Throughout this project, it is expected that you will use a CNN network that is pretrained and use transfer learning in order to train the network to perform the binary classification task. Notably, there are other ways to perfrom this task that are generally better approaches, and exploration of other approaches is left as an optional exercise. \n",
    "\n",
    "You can use any resources at your disposal, including youtube, blog posts, chatgpt etc to complete the project. This is meant to be an easy project that we can discuss about during a later interview. The open ended part of the problem is significantly more challenging however.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Download the Concrete Crack Dataset from the provided link: https://data.mendeley.com/datasets/5y9wdsg2zt/2\n",
    "Extract the dataset and explore its structure.\n",
    "Identify the folders containing the positive and negative samples.\n",
    "Visualize a few samples from each class to understand the data.\n",
    "\n",
    "The dataset is composed of 20,000 negative examples and 20,000 positive examples so the class imbalance is non-issue\n",
    "\n",
    "Since this is a classification problem, you may use pretrained backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Preprocessing/Building Data Loaders\n",
    "\n",
    "Often times it might be helpful to preprocess the data. Things like normalization, resizing, other types of augmentation can be done. \n",
    "\n",
    "During training, data augmentation can be done on the fly to artificially increase the size of the dataset. You can use Pytorch's torchvision transforms in order to do this very easily. Here's the documentation: https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html\n",
    "\n",
    "There is a long list of transforms that can be applied, choose some to try out, and reason about why you might want to choose those.\n",
    "\n",
    "Afterwards, you can build a DataLoader object which helps with the training process to load the data in set batches:\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "Pytorch lightning works with objects called \"DataModules\" which you should implement to load the train/val/test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Creation\n",
    "\n",
    "The basic idea here is to do a standard transfer learning process whereby you change the last layer of a classifier CNN model and train it yourself.\n",
    "\n",
    "As a hint, you can use Resnet18 and simply change the last layer called \"fc\" to begin building the model. This should not require a lot of code to do so.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class NeuralNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self,x):\n",
    "        pass\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        pass        \n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training\n",
    "\n",
    "You will need to work with Pytorch Lightning DataModules, Lightning Modules, and Trainers to begin training. Once you have those objects a simple call to the trainer is possible. You will want to figure out how to monitor metrics if you want to experiment with different training strategies. WANDB is a good library that we use internally to track the progress, you can do this as an optional assignment (it is not hard to implement).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Review Results\n",
    "\n",
    "Looking at the results what do you think are the key metrics that tell you whether this model is good or bad?\n",
    "\n",
    "What other testing would you try to implement to ensure the model is accurate in real life?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Deploy a server endpoint\n",
    "Using FASTAPI you can easily deploy a server endpoint to allow your model to run. Note that this will require you to organize your inference code so that it can be used in handling requests. This is a practical step of the machine learning deployment process, since other applications may want to interface with your prediction engine. \n",
    "\n",
    "Following is the example of code that would exist on a server (which processes the machine learning code). Running this inside a \".py\" file will start a server in the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, Request\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "app = FastAPI()\n",
    "\n",
    "def res2dict():\n",
    "    '''\n",
    "    Convert the output of the model into a serializable format for request\n",
    "    '''\n",
    "    # Start code here\n",
    "    pass \n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def inference(request: Request):\n",
    "    output_dict = {'status': 'server is running'}\n",
    "    return output_dict\n",
    "\n",
    "@app.post(\"/inference\")\n",
    "async def inference(request: Request):\n",
    "\n",
    "    # Get the request and convert to PIL image\n",
    "    data = await request.json()  # Get the json\n",
    "    img_str = data.get(\"img\")  # Get the image as base64 encoded string\n",
    "    img_bytes = base64.b64decode(img_str)\n",
    "    img = Image.open(BytesIO(img_bytes))  # Read as if it were a file\n",
    "\n",
    "    # Run the image through\n",
    "    res = model.predict(img) # Your model prediction functions would be here\n",
    "    output_dict = res2dict(res)\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        app,\n",
    "        port=8000,\n",
    "        host=\"0.0.0.0\",\n",
    "        reload=True,\n",
    "        reload_dirs=[\"src\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a request to the server\n",
    "Assuming the server runs, you can now send images to the endpoint and get predictions back in the form of JSON. Below is example of that client code. Notably, you can use pretty much anything to send the request, but this is what it looks like in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def img2str(img: Image) -> str: \n",
    "    ''' \n",
    "    Encoding function to get base64 image string\n",
    "    '''\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")  # Save into the bytes object\n",
    "\n",
    "    encoded_img = base64.b64encode(buffered.getvalue())  # Save the encoding as byetes\n",
    "    encoded_str = encoded_img.decode(\"utf-8\")  # Decode into a string\n",
    "    return encoded_str\n",
    "\n",
    "\n",
    "img = Image.open(\"data/city-scape.png\")\n",
    "img_str = img2str(img) \n",
    "payload = {\"img\": img_str}\n",
    "\n",
    "# Endpoint of the server\n",
    "url = \"http://127.0.0.1:8000/inference\"\n",
    "\n",
    "# Get the\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json().get(\"detections\")) # Get the relevant key that contains detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Few shot learning\n",
    "\n",
    "Suppose now that instead of a balanced 50/50 data set between good and bad, we now have instead 20,000 good examples, and 50 bad (cracked) examples.\n",
    "\n",
    "How would this change your strategy around model building/training?\n",
    "\n",
    "What other approaches might be more suitable?\n",
    "\n",
    "Any attempts to address this problem, even ones that are purely conceptual, will be considered extra credit. If you decide to develop an algorithm, do not feel constrained to need to use the standard \"classification\" transfer learning paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Docker Deployment\n",
    "\n",
    "You may want to use Docker to containerize your server in production. The reasons for this are many, but include:\n",
    "\n",
    "- replicate errors for debug\n",
    "- make the software more portable\n",
    "- allow for scaling on cloud\n",
    "- development inside containers (allows you to develop/debug in the container itself)\n",
    "\n",
    "You will need to download and install Docker Desktop to do this. Below is a template dockerfile that you can use to build a server. You may have to change which paths are copied into the container on build.\n",
    "\n",
    "Building a container looks something like this:\n",
    "```\n",
    "docker build . -t container_name\n",
    "```\n",
    "\n",
    "Afterwards, you should be able to run the container with:\n",
    "\n",
    "```\n",
    "docker run -p 8000:8000 container_name\n",
    "```\n",
    "\n",
    "Now your server is online, on port 8000 allowing you to perform model inference inside a container. Anyone else will now be able to run your container and do inference with your models!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.8\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y --no-install-recommends \\\n",
    "    libgl1 libgl1-mesa-glx \\\n",
    "    libglib2.0-0 \n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Dependencies\n",
    "RUN python -m pip install -U pip\n",
    "\n",
    "# Copy requirements\n",
    "COPY requirements.txt requirements.txt\n",
    "# Install requirements\n",
    "RUN --mount=type=ssh pip install -r requirements.txt\n",
    "\n",
    "# Copy the server code\n",
    "COPY ./server.py ./server.py \n",
    "# Copy model weights\n",
    "COPY ./yolov5s.pt ./yolov5s.pt\n",
    "\n",
    "CMD [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
